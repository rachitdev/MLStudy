{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# settings to see the data.\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']] = scaler.fit_transform(df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = df[df.Class.eq(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df[df.Class.eq(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_norm = df_norm.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_fraud = df_fraud.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val_norm.append(df_val_fraud, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_val[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = df_norm.iloc[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fraud = df_fraud.iloc[:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_norm.append(df_train_fraud, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_x = X.columns\n",
    "col_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_y = y.columns\n",
    "col_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "oversample = ADASYN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = col_x\n",
    "y.columns = col_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,test_size=0.3,random_state=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Class</td>      <th>  No. Observations:  </th>  <td>397799</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>397769</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 21 Jun 2020</td> <th>  Deviance:          </th> <td>     inf</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>01:32:30</td>     <th>  Pearson chi2:      </th> <td>4.50e+15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>2</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>   -1.9935</td> <td>    0.006</td> <td> -337.778</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>     <td>   -0.5339</td> <td>    0.006</td> <td>  -84.877</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>     <td>   -0.1085</td> <td>    0.006</td> <td>  -18.338</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>     <td>    0.2002</td> <td>    0.006</td> <td>   35.956</td> <td> 0.000</td> <td>    0.189</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>     <td>    0.9905</td> <td>    0.005</td> <td>  202.605</td> <td> 0.000</td> <td>    0.981</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5</th>     <td>   -0.4420</td> <td>    0.006</td> <td>  -75.522</td> <td> 0.000</td> <td>   -0.453</td> <td>   -0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>     <td>   -0.0201</td> <td>    0.006</td> <td>   -3.460</td> <td> 0.001</td> <td>   -0.031</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>     <td>    0.1487</td> <td>    0.005</td> <td>   31.577</td> <td> 0.000</td> <td>    0.139</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>     <td>   -0.2155</td> <td>    0.003</td> <td>  -65.955</td> <td> 0.000</td> <td>   -0.222</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>     <td>   -0.0178</td> <td>    0.005</td> <td>   -3.557</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>    <td>   -0.1023</td> <td>    0.005</td> <td>  -22.154</td> <td> 0.000</td> <td>   -0.111</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>    <td>    0.2685</td> <td>    0.004</td> <td>   60.626</td> <td> 0.000</td> <td>    0.260</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>    <td>   -0.3148</td> <td>    0.005</td> <td>  -67.480</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th>    <td>   -0.3068</td> <td>    0.004</td> <td>  -69.091</td> <td> 0.000</td> <td>   -0.316</td> <td>   -0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th>    <td>   -0.5885</td> <td>    0.004</td> <td> -137.937</td> <td> 0.000</td> <td>   -0.597</td> <td>   -0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V15</th>    <td>    0.3349</td> <td>    0.004</td> <td>   77.797</td> <td> 0.000</td> <td>    0.326</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V16</th>    <td>    0.0259</td> <td>    0.005</td> <td>    5.600</td> <td> 0.000</td> <td>    0.017</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V17</th>    <td>    0.1515</td> <td>    0.003</td> <td>   49.410</td> <td> 0.000</td> <td>    0.145</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V18</th>    <td>    0.2085</td> <td>    0.005</td> <td>   42.757</td> <td> 0.000</td> <td>    0.199</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V19</th>    <td>   -0.1092</td> <td>    0.004</td> <td>  -26.253</td> <td> 0.000</td> <td>   -0.117</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V20</th>    <td>   -0.1749</td> <td>    0.005</td> <td>  -34.787</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V21</th>    <td>   -0.0089</td> <td>    0.004</td> <td>   -2.138</td> <td> 0.033</td> <td>   -0.017</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V22</th>    <td>    0.1145</td> <td>    0.005</td> <td>   22.213</td> <td> 0.000</td> <td>    0.104</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V23</th>    <td>    0.1162</td> <td>    0.005</td> <td>   23.651</td> <td> 0.000</td> <td>    0.107</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V24</th>    <td>   -0.2616</td> <td>    0.005</td> <td>  -48.707</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V25</th>    <td>    0.5819</td> <td>    0.005</td> <td>  116.259</td> <td> 0.000</td> <td>    0.572</td> <td>    0.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V26</th>    <td>   -0.3441</td> <td>    0.005</td> <td>  -66.949</td> <td> 0.000</td> <td>   -0.354</td> <td>   -0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V27</th>    <td>   -0.0613</td> <td>    0.004</td> <td>  -13.785</td> <td> 0.000</td> <td>   -0.070</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V28</th>    <td>   -0.0024</td> <td>    0.006</td> <td>   -0.431</td> <td> 0.667</td> <td>   -0.014</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Amount</th> <td>   -0.1499</td> <td>    0.006</td> <td>  -26.459</td> <td> 0.000</td> <td>   -0.161</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   No. Observations:               397799\n",
       "Model:                            GLM   Df Residuals:                   397769\n",
       "Model Family:                Binomial   Df Model:                           29\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                    nan\n",
       "Date:                Sun, 21 Jun 2020   Deviance:                          inf\n",
       "Time:                        01:32:30   Pearson chi2:                 4.50e+15\n",
       "No. Iterations:                     2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.9935      0.006   -337.778      0.000      -2.005      -1.982\n",
       "V1            -0.5339      0.006    -84.877      0.000      -0.546      -0.522\n",
       "V2            -0.1085      0.006    -18.338      0.000      -0.120      -0.097\n",
       "V3             0.2002      0.006     35.956      0.000       0.189       0.211\n",
       "V4             0.9905      0.005    202.605      0.000       0.981       1.000\n",
       "V5            -0.4420      0.006    -75.522      0.000      -0.453      -0.431\n",
       "V6            -0.0201      0.006     -3.460      0.001      -0.031      -0.009\n",
       "V7             0.1487      0.005     31.577      0.000       0.139       0.158\n",
       "V8            -0.2155      0.003    -65.955      0.000      -0.222      -0.209\n",
       "V9            -0.0178      0.005     -3.557      0.000      -0.028      -0.008\n",
       "V10           -0.1023      0.005    -22.154      0.000      -0.111      -0.093\n",
       "V11            0.2685      0.004     60.626      0.000       0.260       0.277\n",
       "V12           -0.3148      0.005    -67.480      0.000      -0.324      -0.306\n",
       "V13           -0.3068      0.004    -69.091      0.000      -0.316      -0.298\n",
       "V14           -0.5885      0.004   -137.937      0.000      -0.597      -0.580\n",
       "V15            0.3349      0.004     77.797      0.000       0.326       0.343\n",
       "V16            0.0259      0.005      5.600      0.000       0.017       0.035\n",
       "V17            0.1515      0.003     49.410      0.000       0.145       0.158\n",
       "V18            0.2085      0.005     42.757      0.000       0.199       0.218\n",
       "V19           -0.1092      0.004    -26.253      0.000      -0.117      -0.101\n",
       "V20           -0.1749      0.005    -34.787      0.000      -0.185      -0.165\n",
       "V21           -0.0089      0.004     -2.138      0.033      -0.017      -0.001\n",
       "V22            0.1145      0.005     22.213      0.000       0.104       0.125\n",
       "V23            0.1162      0.005     23.651      0.000       0.107       0.126\n",
       "V24           -0.2616      0.005    -48.707      0.000      -0.272      -0.251\n",
       "V25            0.5819      0.005    116.259      0.000       0.572       0.592\n",
       "V26           -0.3441      0.005    -66.949      0.000      -0.354      -0.334\n",
       "V27           -0.0613      0.004    -13.785      0.000      -0.070      -0.053\n",
       "V28           -0.0024      0.006     -0.431      0.667      -0.014       0.009\n",
       "Amount        -0.1499      0.006    -26.459      0.000      -0.161      -0.139\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model, first training model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(logreg, 15)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True, False,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V1', False, 13),\n",
       " ('V2', False, 7),\n",
       " ('V3', True, 1),\n",
       " ('V4', True, 1),\n",
       " ('V5', True, 1),\n",
       " ('V6', True, 1),\n",
       " ('V7', False, 9),\n",
       " ('V8', True, 1),\n",
       " ('V9', True, 1),\n",
       " ('V10', True, 1),\n",
       " ('V11', True, 1),\n",
       " ('V12', True, 1),\n",
       " ('V13', False, 5),\n",
       " ('V14', True, 1),\n",
       " ('V15', False, 6),\n",
       " ('V16', True, 1),\n",
       " ('V17', True, 1),\n",
       " ('V18', False, 12),\n",
       " ('V19', False, 15),\n",
       " ('V20', True, 1),\n",
       " ('V21', False, 14),\n",
       " ('V22', False, 10),\n",
       " ('V23', False, 2),\n",
       " ('V24', True, 1),\n",
       " ('V25', True, 1),\n",
       " ('V26', False, 3),\n",
       " ('V27', False, 11),\n",
       " ('V28', False, 4),\n",
       " ('Amount', False, 8)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(col_x, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V3', 'V4', 'V5', 'V6', 'V8', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16',\n",
       "       'V17', 'V20', 'V24', 'V25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = col_x[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V7', 'V13', 'V15', 'V18', 'V19', 'V21', 'V22', 'V23',\n",
       "       'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_x[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Class</td>      <th>  No. Observations:  </th>  <td>397799</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>397783</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 21 Jun 2020</td> <th>  Deviance:          </th> <td>     inf</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>01:35:03</td>     <th>  Pearson chi2:      </th> <td>4.50e+15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>3</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -2.1535</td> <td>    0.007</td> <td> -308.580</td> <td> 0.000</td> <td>   -2.167</td> <td>   -2.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>    <td>    0.5755</td> <td>    0.006</td> <td>  101.932</td> <td> 0.000</td> <td>    0.564</td> <td>    0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>    <td>    1.1911</td> <td>    0.006</td> <td>  213.174</td> <td> 0.000</td> <td>    1.180</td> <td>    1.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5</th>    <td>   -0.5087</td> <td>    0.007</td> <td>  -76.824</td> <td> 0.000</td> <td>   -0.522</td> <td>   -0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>    <td>   -0.2721</td> <td>    0.007</td> <td>  -36.425</td> <td> 0.000</td> <td>   -0.287</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>    <td>   -0.3879</td> <td>    0.003</td> <td> -117.811</td> <td> 0.000</td> <td>   -0.394</td> <td>   -0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>    <td>   -0.2518</td> <td>    0.005</td> <td>  -45.915</td> <td> 0.000</td> <td>   -0.263</td> <td>   -0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>   <td>   -0.4353</td> <td>    0.005</td> <td>  -79.722</td> <td> 0.000</td> <td>   -0.446</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>   <td>    0.3506</td> <td>    0.005</td> <td>   76.419</td> <td> 0.000</td> <td>    0.342</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>   <td>   -0.5213</td> <td>    0.005</td> <td> -104.593</td> <td> 0.000</td> <td>   -0.531</td> <td>   -0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th>   <td>   -0.7279</td> <td>    0.005</td> <td> -151.784</td> <td> 0.000</td> <td>   -0.737</td> <td>   -0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V16</th>   <td>    0.0018</td> <td>    0.005</td> <td>    0.386</td> <td> 0.700</td> <td>   -0.007</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V17</th>   <td>    0.3639</td> <td>    0.003</td> <td>  107.727</td> <td> 0.000</td> <td>    0.357</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V20</th>   <td>   -0.1983</td> <td>    0.005</td> <td>  -39.917</td> <td> 0.000</td> <td>   -0.208</td> <td>   -0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V24</th>   <td>   -0.4250</td> <td>    0.006</td> <td>  -65.774</td> <td> 0.000</td> <td>   -0.438</td> <td>   -0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V25</th>   <td>    0.5949</td> <td>    0.006</td> <td>  106.271</td> <td> 0.000</td> <td>    0.584</td> <td>    0.606</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   No. Observations:               397799\n",
       "Model:                            GLM   Df Residuals:                   397783\n",
       "Model Family:                Binomial   Df Model:                           15\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                    nan\n",
       "Date:                Sun, 21 Jun 2020   Deviance:                          inf\n",
       "Time:                        01:35:03   Pearson chi2:                 4.50e+15\n",
       "No. Iterations:                     3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -2.1535      0.007   -308.580      0.000      -2.167      -2.140\n",
       "V3             0.5755      0.006    101.932      0.000       0.564       0.587\n",
       "V4             1.1911      0.006    213.174      0.000       1.180       1.202\n",
       "V5            -0.5087      0.007    -76.824      0.000      -0.522      -0.496\n",
       "V6            -0.2721      0.007    -36.425      0.000      -0.287      -0.257\n",
       "V8            -0.3879      0.003   -117.811      0.000      -0.394      -0.381\n",
       "V9            -0.2518      0.005    -45.915      0.000      -0.263      -0.241\n",
       "V10           -0.4353      0.005    -79.722      0.000      -0.446      -0.425\n",
       "V11            0.3506      0.005     76.419      0.000       0.342       0.360\n",
       "V12           -0.5213      0.005   -104.593      0.000      -0.531      -0.512\n",
       "V14           -0.7279      0.005   -151.784      0.000      -0.737      -0.719\n",
       "V16            0.0018      0.005      0.386      0.700      -0.007       0.011\n",
       "V17            0.3639      0.003    107.727      0.000       0.357       0.371\n",
       "V20           -0.1983      0.005    -39.917      0.000      -0.208      -0.189\n",
       "V24           -0.4250      0.006    -65.774      0.000      -0.438      -0.412\n",
       "V25            0.5949      0.006    106.271      0.000       0.584       0.606\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the probablity column\n",
    "\n",
    "Now we add the probablity column as well as the prediction column in order to make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239371    0.035984\n",
       "267770    0.007413\n",
       "498983    0.812996\n",
       "306770    0.619247\n",
       "227598    0.042415\n",
       "65574     0.957213\n",
       "330477    0.967387\n",
       "498844    0.563356\n",
       "229267    0.837026\n",
       "99858     0.125470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-7ffc0ee940e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train_pred_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Fraud'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fraud_Prob'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# from BlockManager perspective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             val = sanitize_array(\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             )\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Fraud':y_train.values, 'Fraud_Prob':y_train_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
