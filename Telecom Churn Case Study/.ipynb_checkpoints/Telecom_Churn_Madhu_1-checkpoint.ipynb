{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Churn case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Problem Statement:\n",
    "\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "- For many incumbent operators, retaining high profitable customers is the number one business goal. \n",
    "- To reduce customer churn, telecom companies need to predict which customers are at high risk of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Requirement:\n",
    "\n",
    "- Analyse customer-level data of a leading telecom firm.\n",
    "- Build predictive models to identify customers at high risk of churn.\n",
    "- Identify the main indicators of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "%matplotlib inline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the telecom churn csv file\n",
    "telecom_churn_df = pd.read_csv(\"telecom_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>968</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>3.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109        0.000000        0.000000        0.000000   \n",
       "1     7001865778        109        0.000000        0.000000        0.000000   \n",
       "2     7001625959        109        0.000000        0.000000        0.000000   \n",
       "3     7001204172        109        0.000000        0.000000        0.000000   \n",
       "4     7000142493        109        0.000000        0.000000        0.000000   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9     arpu_6  ...  sachet_3g_9  fb_user_6  fb_user_7  \\\n",
       "0            9/30/2014 197.385000  ...            0   1.000000   1.000000   \n",
       "1            9/30/2014  34.047000  ...            0        nan   1.000000   \n",
       "2            9/30/2014 167.690000  ...            0        nan        nan   \n",
       "3            9/30/2014 221.338000  ...            0        nan        nan   \n",
       "4            9/30/2014 261.636000  ...            0   0.000000        nan   \n",
       "\n",
       "   fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  \n",
       "0   1.000000        nan   968   30.400000    0.000000  101.200000    3.580000  \n",
       "1   1.000000        nan  1006    0.000000    0.000000    0.000000    0.000000  \n",
       "2        nan   1.000000  1103    0.000000    0.000000    4.170000    0.000000  \n",
       "3        nan        nan  2491    0.000000    0.000000    0.000000    0.000000  \n",
       "4        nan        nan  1526    0.000000    0.000000    0.000000    0.000000  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique elements in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobile_number           99999\n",
      "circle_id                   1\n",
      "loc_og_t2o_mou              1\n",
      "std_og_t2o_mou              1\n",
      "loc_ic_t2o_mou              1\n",
      "last_date_of_month_6        1\n",
      "last_date_of_month_7        1\n",
      "last_date_of_month_8        1\n",
      "last_date_of_month_9        1\n",
      "arpu_6                  85681\n",
      "arpu_7                  85308\n",
      "arpu_8                  83615\n",
      "arpu_9                  79937\n",
      "onnet_mou_6             24313\n",
      "onnet_mou_7             24336\n",
      "onnet_mou_8             24089\n",
      "onnet_mou_9             23565\n",
      "offnet_mou_6            31140\n",
      "offnet_mou_7            31023\n",
      "offnet_mou_8            30908\n",
      "offnet_mou_9            30077\n",
      "roam_ic_mou_6            6512\n",
      "roam_ic_mou_7            5230\n",
      "roam_ic_mou_8            5315\n",
      "roam_ic_mou_9            4827\n",
      "roam_og_mou_6            8038\n",
      "roam_og_mou_7            6639\n",
      "roam_og_mou_8            6504\n",
      "roam_og_mou_9            5882\n",
      "loc_og_t2t_mou_6        13539\n",
      "                        ...  \n",
      "arpu_2g_9                6795\n",
      "night_pck_user_6            2\n",
      "night_pck_user_7            2\n",
      "night_pck_user_8            2\n",
      "night_pck_user_9            2\n",
      "monthly_2g_6                5\n",
      "monthly_2g_7                6\n",
      "monthly_2g_8                6\n",
      "monthly_2g_9                5\n",
      "sachet_2g_6                32\n",
      "sachet_2g_7                35\n",
      "sachet_2g_8                34\n",
      "sachet_2g_9                32\n",
      "monthly_3g_6               12\n",
      "monthly_3g_7               15\n",
      "monthly_3g_8               12\n",
      "monthly_3g_9               11\n",
      "sachet_3g_6                25\n",
      "sachet_3g_7                27\n",
      "sachet_3g_8                29\n",
      "sachet_3g_9                27\n",
      "fb_user_6                   2\n",
      "fb_user_7                   2\n",
      "fb_user_8                   2\n",
      "fb_user_9                   2\n",
      "aon                      3489\n",
      "aug_vbc_3g              14676\n",
      "jul_vbc_3g              14162\n",
      "jun_vbc_3g              13312\n",
      "sep_vbc_3g               3720\n",
      "Length: 226, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique = telecom_churn_df.nunique()\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate columns with just 1 value\n",
    "telecom_churn_df = telecom_churn_df[unique.index[unique.values>1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values in the data columnwise\n",
    "perc_na=round(100*(telecom_churn_df.isnull().sum()/len(telecom_churn_df.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['Name']\n",
    "perc_na_df=pd.DataFrame(perc_na,columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns having 0-5% null values\n",
    "na_5 = perc_na_df[(perc_na_df['Name']<5.000) & (perc_na_df['Name']>00.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns having 5-10% null values\n",
    "na_10 = perc_na_df[(perc_na_df['Name']<10.000) & (perc_na_df['Name']>05.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns having more than 70% null values\n",
    "na_70 = perc_na_df[(perc_na_df['Name']>70.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for columns having between 10-70% null values\n",
    "perc_na_df[(perc_na_df['Name']>10.000) & (perc_na_df['Name']<70.000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Columns with 10-70% Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the columns which have more than 70% null values\n",
    "perc_na_df[perc_na_df['Name']>70.000].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_of_last_rech_data_6 -- ['6/21/2014' nan '6/4/2014' '6/27/2014' '6/30/2014' '6/6/2014' '6/2/2014'\n",
      " '6/12/2014' '6/19/2014' '6/29/2014' '6/5/2014' '6/17/2014' '6/11/2014'\n",
      " '6/25/2014' '6/10/2014' '6/20/2014' '6/23/2014' '6/13/2014' '6/26/2014'\n",
      " '6/16/2014' '6/14/2014' '6/24/2014' '6/28/2014' '6/15/2014' '6/9/2014'\n",
      " '6/22/2014' '6/1/2014' '6/8/2014' '6/7/2014' '6/18/2014' '6/3/2014']\n",
      "date_of_last_rech_data_7 -- ['7/16/2014' '7/25/2014' nan '7/31/2014' '7/23/2014' '7/7/2014'\n",
      " '7/27/2014' '7/2/2014' '7/28/2014' '7/12/2014' '7/4/2014' '7/5/2014'\n",
      " '7/6/2014' '7/26/2014' '7/19/2014' '7/10/2014' '7/11/2014' '7/29/2014'\n",
      " '7/18/2014' '7/9/2014' '7/24/2014' '7/14/2014' '7/13/2014' '7/22/2014'\n",
      " '7/30/2014' '7/20/2014' '7/21/2014' '7/15/2014' '7/8/2014' '7/17/2014'\n",
      " '7/1/2014' '7/3/2014']\n",
      "date_of_last_rech_data_8 -- ['8/8/2014' '8/10/2014' nan '8/23/2014' '8/24/2014' '8/21/2014'\n",
      " '8/30/2014' '8/6/2014' '8/25/2014' '8/7/2014' '8/26/2014' '8/11/2014'\n",
      " '8/2/2014' '8/31/2014' '8/20/2014' '8/29/2014' '8/17/2014' '8/14/2014'\n",
      " '8/28/2014' '8/3/2014' '8/15/2014' '8/18/2014' '8/19/2014' '8/27/2014'\n",
      " '8/13/2014' '8/22/2014' '8/1/2014' '8/9/2014' '8/16/2014' '8/12/2014'\n",
      " '8/4/2014' '8/5/2014']\n",
      "date_of_last_rech_data_9 -- [nan '9/17/2014' '9/1/2014' '9/9/2014' '9/21/2014' '9/10/2014' '9/26/2014'\n",
      " '9/12/2014' '9/29/2014' '9/6/2014' '9/20/2014' '9/23/2014' '9/3/2014'\n",
      " '9/30/2014' '9/8/2014' '9/27/2014' '9/28/2014' '9/24/2014' '9/14/2014'\n",
      " '9/18/2014' '9/19/2014' '9/2/2014' '9/22/2014' '9/25/2014' '9/16/2014'\n",
      " '9/15/2014' '9/13/2014' '9/5/2014' '9/4/2014' '9/7/2014' '9/11/2014']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "count_rech_2g_6 -- [ 0. nan  1.  3.  4.  2.  7.  8. 12.  5. 16. 11.  6. 10. 20.  9. 18. 19.\n",
      " 22. 14. 17. 13. 15. 21. 25. 32. 39. 24. 28. 30. 42. 34.]\n",
      "count_rech_2g_7 -- [ 0.  1. nan  2.  5. 12.  7.  3.  6. 10.  8.  4. 16. 11.  9. 13. 15. 29.\n",
      " 22. 14. 23. 17. 21. 19. 20. 18. 26. 27. 30. 25. 28. 31. 32. 48. 43. 35.\n",
      " 24.]\n",
      "count_rech_2g_8 -- [ 0.  2. nan  3.  1. 16.  7.  4.  5. 13. 15. 24.  6. 12.  9. 10. 14.  8.\n",
      " 27. 11. 18. 29. 22. 17. 19. 26. 25. 21. 33. 34. 20. 44. 32. 31. 23.]\n",
      "count_rech_2g_9 -- [nan  1.  0.  2.  3.  5.  6.  8.  7. 11. 12.  4.  9. 10. 14. 33. 35. 13.\n",
      " 22. 15. 18. 24. 21. 16. 27. 40. 30. 25. 32. 20. 23. 17. 19.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "count_rech_3g_6 -- [ 1. nan  0.  5.  3.  2.  8.  4.  6. 10. 22.  7. 13. 11. 29. 16. 18. 12.\n",
      " 19.  9. 23. 14. 17. 15. 21. 28.]\n",
      "count_rech_3g_7 -- [ 1.  0. nan  2.  8.  4.  3.  5.  7. 20. 15.  6. 10. 12. 17. 23. 22. 11.\n",
      "  9. 13. 19. 14. 21. 24. 18. 35. 34. 16. 31.]\n",
      "count_rech_3g_8 -- [ 1.  0. nan  2.  3.  5.  7.  4. 23. 30. 13.  6.  8. 10. 24. 12. 25. 15.\n",
      " 16.  9. 14. 45. 19. 21. 18. 11. 17. 20. 29. 42.]\n",
      "count_rech_3g_9 -- [nan  0.  1.  2.  3.  5.  8.  4.  6. 11. 49. 23.  7. 10. 18. 24. 19.  9.\n",
      " 21. 22. 12. 13. 15. 39. 14. 26. 16. 27.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "total_rech_data_6 -- [ 1. nan  3.  5.  4.  2.  6.  8.  7. 12. 16. 11. 10. 14. 20.  9. 18. 29.\n",
      " 23. 15. 22. 27. 17. 21. 13. 19. 35. 25. 33. 61. 55. 24. 26. 28. 40. 32.\n",
      " 46. 34.]\n",
      "total_rech_data_7 -- [ 1. nan  2.  8.  5. 12.  7.  4.  6.  3. 10. 16. 11.  9. 13. 29. 15. 42.\n",
      " 17. 14. 23. 22. 20. 19. 21. 32. 25. 18. 26. 24. 48. 35. 30. 27. 43. 31.\n",
      " 39. 44. 40. 50. 34. 37. 54.]\n",
      "total_rech_data_8 -- [ 1.  2. nan  3. 16.  7.  4.  6.  5. 13. 17. 15. 24. 14. 12.  9.  8. 10.\n",
      " 50. 11. 18. 57. 20. 28. 29. 46. 23. 25. 22. 26. 19. 32. 49. 42. 48. 39.\n",
      " 40. 34. 44. 27. 38. 21. 30. 33. 60. 37. 55.]\n",
      "total_rech_data_9 -- [nan  1.  2.  3.  4.  5.  6.  8.  7. 12.  9. 11. 14. 33. 10. 84. 13. 27.\n",
      " 32. 20. 18. 19. 24. 16. 21. 26. 15. 30. 17. 41. 38. 40. 31. 52. 22. 23.\n",
      " 51. 28.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "max_rech_data_6 -- [2.520e+02       nan 5.600e+01 1.540e+02 2.500e+01 2.740e+02 1.980e+02\n",
      " 2.300e+01 1.400e+01 6.550e+02 9.800e+01 1.250e+02 4.100e+01 1.450e+02\n",
      " 4.600e+01 1.520e+02 1.700e+01 4.900e+01 9.100e+01 1.790e+02 1.490e+02\n",
      " 2.900e+01 1.770e+02 4.550e+02 8.000e+00 1.000e+00 3.300e+01 1.500e+01\n",
      " 5.050e+02 4.800e+01 2.020e+02 4.490e+02 6.100e+01 2.200e+01 5.200e+01\n",
      " 7.550e+02 5.000e+00 1.010e+02 9.000e+00 9.510e+02 2.950e+02 1.555e+03\n",
      " 1.505e+03 8.550e+02 9.950e+02 1.300e+01 1.255e+03 1.480e+02 4.950e+02]\n",
      "max_rech_data_7 -- [2.520e+02 1.540e+02       nan 1.790e+02 2.500e+01 1.255e+03 4.100e+01\n",
      " 2.300e+01 1.700e+01 6.550e+02 4.550e+02 9.800e+01 1.980e+02 1.450e+02\n",
      " 1.520e+02 1.770e+02 2.900e+01 9.100e+01 1.400e+01 4.800e+01 8.000e+00\n",
      " 2.740e+02 1.490e+02 4.600e+01 4.900e+01 3.300e+01 1.250e+02 4.490e+02\n",
      " 5.600e+01 1.000e+00 2.020e+02 5.000e+00 2.200e+01 5.050e+02 5.200e+01\n",
      " 9.000e+00 7.550e+02 1.010e+02 6.100e+01 1.500e+01 1.555e+03 9.510e+02\n",
      " 8.550e+02 1.300e+01 2.950e+02 1.505e+03 9.950e+02 6.750e+02 7.950e+02]\n",
      "max_rech_data_8 -- [2.520e+02 2.500e+01       nan 2.300e+01 1.700e+01 1.540e+02 2.740e+02\n",
      " 1.790e+02 4.100e+01 4.550e+02 1.450e+02 9.800e+01 1.980e+02 1.750e+02\n",
      " 1.520e+02 2.900e+01 9.100e+01 1.640e+02 4.600e+01 8.000e+00 1.400e+01\n",
      " 3.300e+01 1.490e+02 5.600e+01 7.550e+02 4.900e+01 1.250e+02 2.020e+02\n",
      " 1.000e+00 1.770e+02 4.490e+02 2.480e+02 4.800e+01 5.200e+01 6.550e+02\n",
      " 2.950e+02 2.200e+01 5.000e+00 6.750e+02 9.510e+02 1.010e+02 5.050e+02\n",
      " 8.550e+02 1.300e+01 1.505e+03 6.100e+01 1.555e+03 1.500e+01 1.255e+03\n",
      " 4.950e+02 9.000e+00]\n",
      "max_rech_data_9 -- [      nan 4.600e+01 1.700e+01 2.520e+02 2.740e+02 6.550e+02 1.490e+02\n",
      " 2.300e+01 1.450e+02 1.790e+02 8.000e+00 9.800e+01 1.540e+02 7.550e+02\n",
      " 1.980e+02 2.500e+01 1.750e+02 1.520e+02 5.600e+01 2.900e+01 9.100e+01\n",
      " 1.250e+02 1.640e+02 4.550e+02 4.100e+01 2.020e+02 3.300e+01 2.480e+02\n",
      " 4.900e+01 2.200e+01 1.400e+01 1.000e+00 4.490e+02 3.480e+02 4.800e+01\n",
      " 2.950e+02 5.050e+02 5.000e+00 9.510e+02 1.555e+03 1.300e+01 1.010e+02\n",
      " 5.200e+01 9.000e+00 8.550e+02 9.950e+02 1.255e+03 1.500e+01 4.950e+02\n",
      " 7.950e+02 1.505e+03]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "arpu_2g_6 -- [212.17    nan   0.   ...  91.82  36.14  18.68]\n",
      "arpu_2g_7 -- [212.17  28.61    nan ...  57.57  79.27   8.43]\n",
      "arpu_2g_8 -- [212.17   7.6     nan ... 425.88 345.9   48.24]\n",
      "arpu_2g_9 -- [       nan 0.0000e+00 4.6000e-01 ... 5.9556e+02 1.0237e+02 7.2568e+02]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "arpu_3g_6 -- [212.17    nan   0.   ...  76.93 141.48 235.68]\n",
      "arpu_3g_7 -- [212.17   0.      nan ... 448.   105.64 262.65]\n",
      "arpu_3g_8 -- [212.17   0.      nan ...  92.18 229.46 602.68]\n",
      "arpu_3g_9 -- [   nan   2.84   0.   ... 803.83  42.89 725.69]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "night_pck_user_6 -- [ 0. nan  1.]\n",
      "night_pck_user_7 -- [ 0. nan  1.]\n",
      "night_pck_user_8-- [ 0. nan  1.]\n",
      "night_pck_user_9 -- [nan  0.  1.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "fb_user_6 -- [ 1. nan  0.]\n",
      "fb_user_7 -- [ 1. nan  0.]\n",
      "fb_user_8 -- [ 1. nan  0.]\n",
      "fb_user_9 -- [nan  1.  0.]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check unique values of each column having null vlaues greater than 70%\n",
    "print(\"date_of_last_rech_data_6 --\", telecom_churn_df.date_of_last_rech_data_6.unique())\n",
    "print(\"date_of_last_rech_data_7 --\", telecom_churn_df.date_of_last_rech_data_7.unique())\n",
    "print(\"date_of_last_rech_data_8 --\", telecom_churn_df.date_of_last_rech_data_8.unique())\n",
    "print(\"date_of_last_rech_data_9 --\", telecom_churn_df.date_of_last_rech_data_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"count_rech_2g_6 --\", telecom_churn_df.count_rech_2g_6.unique())\n",
    "print(\"count_rech_2g_7 --\", telecom_churn_df.count_rech_2g_7.unique())\n",
    "print(\"count_rech_2g_8 --\", telecom_churn_df.count_rech_2g_8.unique())\n",
    "print(\"count_rech_2g_9 --\", telecom_churn_df.count_rech_2g_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"count_rech_3g_6 --\", telecom_churn_df.count_rech_3g_6.unique())\n",
    "print(\"count_rech_3g_7 --\", telecom_churn_df.count_rech_3g_7.unique())\n",
    "print(\"count_rech_3g_8 --\", telecom_churn_df.count_rech_3g_8.unique())\n",
    "print(\"count_rech_3g_9 --\", telecom_churn_df.count_rech_3g_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"total_rech_data_6 --\", telecom_churn_df.total_rech_data_6.unique())\n",
    "print(\"total_rech_data_7 --\", telecom_churn_df.total_rech_data_7.unique())\n",
    "print(\"total_rech_data_8 --\", telecom_churn_df.total_rech_data_8.unique())\n",
    "print(\"total_rech_data_9 --\", telecom_churn_df.total_rech_data_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"max_rech_data_6 --\", telecom_churn_df.max_rech_data_6.unique())\n",
    "print(\"max_rech_data_7 --\", telecom_churn_df.max_rech_data_7.unique())\n",
    "print(\"max_rech_data_8 --\", telecom_churn_df.max_rech_data_8.unique())\n",
    "print(\"max_rech_data_9 --\", telecom_churn_df.max_rech_data_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"arpu_2g_6 --\", telecom_churn_df.arpu_2g_6.unique())\n",
    "print(\"arpu_2g_7 --\", telecom_churn_df.arpu_2g_7.unique())\n",
    "print(\"arpu_2g_8 --\", telecom_churn_df.arpu_2g_8.unique())\n",
    "print(\"arpu_2g_9 --\", telecom_churn_df.arpu_2g_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"arpu_3g_6 --\", telecom_churn_df.arpu_3g_6.unique())\n",
    "print(\"arpu_3g_7 --\", telecom_churn_df.arpu_3g_7.unique())\n",
    "print(\"arpu_3g_8 --\", telecom_churn_df.arpu_3g_8.unique())\n",
    "print(\"arpu_3g_9 --\", telecom_churn_df.arpu_3g_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"night_pck_user_6 --\", telecom_churn_df.night_pck_user_6.unique())\n",
    "print(\"night_pck_user_7 --\", telecom_churn_df.night_pck_user_7.unique())\n",
    "print(\"night_pck_user_8--\", telecom_churn_df.night_pck_user_8.unique())\n",
    "print(\"night_pck_user_9 --\", telecom_churn_df.night_pck_user_9.unique())\n",
    "print(\"-\"*100)\n",
    "print(\"fb_user_6 --\", telecom_churn_df.fb_user_6.unique())\n",
    "print(\"fb_user_7 --\", telecom_churn_df.fb_user_7.unique())\n",
    "print(\"fb_user_8 --\", telecom_churn_df.fb_user_8.unique())\n",
    "print(\"fb_user_9 --\", telecom_churn_df.fb_user_9.unique())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As Night pack user and fb user columns have only 0 and 1s. Let's impute by adding min value\n",
    "for column in telecom_churn_df.filter(regex ='user').columns:\n",
    "    telecom_churn_df[column].replace(np.nan, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column with > 70% missing values\n",
    "telecom_churn_df.drop(na_70.index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After imputing all the variables having null values more than 70%, let's verify the null values which are above 70%\n",
    "perc_na=round(100*(telecom_churn_df.isnull().sum()/len(telecom_churn_df.index)), 2)\n",
    "perc_na.where(perc_na>10).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 170)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*(telecom_churn_df.isnull().sum()/len(telecom_churn_df.index)), 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute date columns\n",
    "date_columns = telecom_churn_df.filter(regex ='date').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in date_columns:\n",
    "    telecom_churn_df[d] = pd.to_datetime(telecom_churn_df[d]).dt.day\n",
    "    telecom_churn_df[d].fillna(int(telecom_churn_df[d].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the type of  variables in data frame\n",
    "telecom_churn_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute columns where nan values % is less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the missing values for variables having upto 10%\n",
    "perc_na_df_10=perc_na_df[(perc_na_df['Name']<10) & (perc_na_df['Name']>0)]\n",
    "perc_na_df_10.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = telecom_churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute remaining values using iterative imputer\n",
    "telecom_churn_df = pd.DataFrame(IterativeImputer().fit_transform(telecom_churn_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if null values exist\n",
    "telecom_churn_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df.columns = columns_name\n",
    "telecom_churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the High Value Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get total recharge amount for 6th and 7th months - Good phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df.total_rech_amt_avg = (telecom_churn_df.total_rech_amt_6 +telecom_churn_df.total_rech_amt_7)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find total recharge amount for 6th and 7th months - Good phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding good phase for filtering HVC\n",
    "telecom_churn_df.total_rech_amt_good_phase=(telecom_churn_df.total_rech_amt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df.total_rech_amt_good_phase.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the 70 percentile of High Value Customer data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_70percentile = telecom_churn_df.total_rech_amt_good_phase.quantile(q=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_70percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetching High Value customer of more than 70th percentile(inclusive) of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high = telecom_churn_df[(telecom_churn_df.total_rech_amt_good_phase >= _70percentile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(telecom_churn_df_high.isnull().sum()/len(telecom_churn_df_high.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Including churn information to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high['usage_9'] = telecom_churn_df_high['total_ic_mou_9'] + telecom_churn_df_high['total_og_mou_9'] + telecom_churn_df_high['vol_3g_mb_9'] + telecom_churn_df_high['vol_2g_mb_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the churn data from 9th(Sept) month of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high[\"churn_data\"] = [1 if value == 0 else 0 for value in telecom_churn_df_high.usage_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high[\"churn_data\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the churn data percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(telecom_churn_df_high[\"churn_data\"].sum()/telecom_churn_df_high[\"churn_data\"].count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 9th(Sept) month columns from data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = telecom_churn_df_high.filter(regex ='9').columns\n",
    "telecom_churn_df_high.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of clean data after finding high value customers\n",
    "telecom_churn_df_high.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out ratio of revenue on happy/action phase\n",
    "telecom_churn_df_high['arpu_ratio'] = ((telecom_churn_df_high.arpu_6 + telecom_churn_df_high.arpu_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.arpu_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out if customer centre call were made more in action phase\n",
    "telecom_churn_df_high['call_centre_ratio'] = ((telecom_churn_df_high.loc_og_t2c_mou_6 + telecom_churn_df_high.loc_og_t2c_mou_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.loc_og_t2c_mou_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out ratio of usage from other network\n",
    "telecom_churn_df_high['network_usage_diff'] = (telecom_churn_df_high.onnet_mou_8) - ( telecom_churn_df_high.offnet_mou_8)\n",
    "# Find out ratio of usage from other network\n",
    "telecom_churn_df_high['network_usage_diff_good'] = (telecom_churn_df_high.onnet_mou_6 + telecom_churn_df_high.onnet_mou_7 - telecom_churn_df_high.offnet_mou_6 - telecom_churn_df_high.offnet_mou_6)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of good/action for 2g\n",
    "telecom_churn_df_high['2g_usage_ratio'] = ((telecom_churn_df_high.vol_2g_mb_6 + telecom_churn_df_high.vol_2g_mb_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.vol_2g_mb_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of good/action for 3g\n",
    "telecom_churn_df_high['3g_usage_ratio'] = ((telecom_churn_df_high.vol_3g_mb_6 + telecom_churn_df_high.vol_3g_mb_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.vol_3g_mb_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of good/action for outgoing call\n",
    "telecom_churn_df_high['og_ratio'] = ((telecom_churn_df_high.total_og_mou_6 + telecom_churn_df_high.total_og_mou_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.total_og_mou_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of good/action for outgoing call\n",
    "telecom_churn_df_high['ic_ratio'] = ((telecom_churn_df_high.total_ic_mou_6 + telecom_churn_df_high.total_ic_mou_7)/2)/[1 if x ==0 else x for x in telecom_churn_df_high.total_ic_mou_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of good/action for vbc\n",
    "telecom_churn_df_high['vbc_difference'] = ((telecom_churn_df_high.jun_vbc_3g + telecom_churn_df_high.jul_vbc_3g)/2) - [1 if x ==0 else x for x in telecom_churn_df_high.aug_vbc_3g]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking variance to see which columns hold most information\n",
    "round(100*(np.var(telecom_churn_df_high.drop('mobile_number' , axis =1))/np.var(telecom_churn_df_high.drop('mobile_number' , axis =1)).sum()), 2).sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis on all column\n",
    "for columns in telecom_churn_df_high.columns:\n",
    "    plt.figure(figsize=(16,3))\n",
    "    column = telecom_churn_df_high[columns]\n",
    "    print(columns)\n",
    "    sns.distplot(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Older customer are more likely to continue\n",
    "telecom_churn_df_high['binned_aon'] = pd.qcut(telecom_churn_df_high['aon'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_aon','churn_data']).count()/telecom_churn_df_high.groupby(['binned_aon']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_aon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers having low arpu in action phase as compared to good phase is likely to churn\n",
    "telecom_churn_df_high['binned_arpu_ratio'] = pd.qcut(telecom_churn_df_high['arpu_ratio'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_arpu_ratio','churn_data']).count()/telecom_churn_df_high.groupby(['binned_arpu_ratio']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_arpu_ratio'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers not using outgoing calls for september are likely to churn\n",
    "telecom_churn_df_high['binned_total_og_mou_8'] = pd.qcut(telecom_churn_df_high['total_og_mou_8'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_total_og_mou_8','churn_data']).count()/telecom_churn_df_high.groupby(['binned_total_og_mou_8']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_total_og_mou_8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers having low arpu in action period is likely to churn\n",
    "telecom_churn_df_high['binned_arpu_8'] = pd.qcut(telecom_churn_df_high['arpu_8'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_arpu_8','churn_data']).count()/telecom_churn_df_high.groupby(['binned_arpu_8']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_arpu_8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers having low arpu in action period is likely to churn\n",
    "telecom_churn_df_high['binned_onnet_mou_8'] = pd.qcut(telecom_churn_df_high['onnet_mou_8'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_onnet_mou_8','churn_data']).count()/telecom_churn_df_high.groupby(['binned_onnet_mou_8']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_onnet_mou_8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers having low arpu in action period is likely to churn\n",
    "telecom_churn_df_high['binned_offnet_mou_8'] = pd.qcut(telecom_churn_df_high['offnet_mou_8'], 10)\n",
    "(round(100*(telecom_churn_df_high.groupby(['binned_offnet_mou_8','churn_data']).count()/telecom_churn_df_high.groupby(['binned_offnet_mou_8']).count()).mobile_number),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.drop(['binned_offnet_mou_8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There must be data which are not significant in predicting the Churn customers in every column and presence of this data would give biased results. Hence we can do outlier treatement to remove such data\n",
    "\n",
    "It is done using 3 sigma technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_treatment = telecom_churn_df_high.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 0.3 percent outliers from data set \n",
    "for columns in telecom_churn_df_high.columns:\n",
    "    column = telecom_churn_df_high[columns]\n",
    "    upper = column.mean() + 3*column.std()\n",
    "    lower = column.mean() - 3*column.std()\n",
    "    outliers = pd.Series([x for x in column if (x < lower) or (x > upper)])\n",
    "    out_percent = (outliers.size/column.size) * 100\n",
    "    if out_percent <= 0.3:\n",
    "        print(out_percent)\n",
    "        telecom_churn_df_high = telecom_churn_df_high[(telecom_churn_df_high[columns] >= lower) & (telecom_churn_df_high[columns] <= upper)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_churn_df_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % data retained after treatment\n",
    "(telecom_churn_df_high.index.size/pre_treatment) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing data\n",
    "\n",
    "- Converting data set into dependant and independant variables for building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = telecom_churn_df_high.drop(['churn_data','mobile_number'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = telecom_churn_df_high['churn_data']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test/train data:\n",
    "- We need to split the data into training and testing set. Models would be run on Training set and validated on testing data set later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name= X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,test_size=0.3,random_state=100) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
